{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/peacehegemony/kaggle-notebook-that-trains-a-model-to-classify?scriptVersionId=118986623\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"d08b8faf","metadata":{"papermill":{"duration":0.004834,"end_time":"2023-02-12T23:37:07.684857","exception":false,"start_time":"2023-02-12T23:37:07.680023","status":"completed"},"tags":[]},"source":["# Here is an example Kaggle notebook that trains a model to classify images of a species or else:"]},{"cell_type":"code","execution_count":1,"id":"533cdba2","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-12T23:37:07.694542Z","iopub.status.busy":"2023-02-12T23:37:07.6939Z","iopub.status.idle":"2023-02-12T23:37:33.448632Z","shell.execute_reply":"2023-02-12T23:37:33.447152Z"},"papermill":{"duration":25.763728,"end_time":"2023-02-12T23:37:33.452246","exception":false,"start_time":"2023-02-12T23:37:07.688518","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-02-12 23:37:15.144460: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","2023-02-12 23:37:15.726746: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","7/7 [==============================] - 3s 274ms/step - loss: 0.0977 - accuracy: 0.9948 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 2/10\n","7/7 [==============================] - 2s 222ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 3/10\n","7/7 [==============================] - 2s 225ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 4/10\n","7/7 [==============================] - 2s 216ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 5/10\n","7/7 [==============================] - 2s 234ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 6/10\n","7/7 [==============================] - 2s 225ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 7/10\n","7/7 [==============================] - 2s 221ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 8/10\n","7/7 [==============================] - 2s 229ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 9/10\n","7/7 [==============================] - 2s 219ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 10/10\n","7/7 [==============================] - 2s 217ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","3/3 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n","\n","Test loss: 0.0\n","Test accuracy: 1.0\n"]}],"source":["# Import necessary libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","\n","\n","\n","# Set path for the dataset\n","path = '/kaggle/input/494-fox-labeled-image-dataset/images.cv_8rk8h3aklzqjr2tcx76b7/data/train/animal fox'\n","\n","\n","# Create list to store the images and labels\n","images = []\n","labels = []\n","\n","\n","# Loop through the directory and read in the images\n","for filename in os.listdir(path):\n","    if filename.endswith('.jpg'):\n","        img = Image.open(path + '/' + filename)\n","        images.append(np.array(img))\n","        labels.append(1) # Assume all images are of foxes\n","\n","\n","# Convert the images and labels to numpy arrays\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","\n","# Normalize the images\n","images = images / 255.0\n","\n","\n","# One-hot encode the labels\n","labels = to_categorical(labels)\n","\n","\n","# Get the shape of the first image to use as input_shape for the first layer\n","img_shape = images[0].shape\n","\n","\n","# Create the model\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=img_shape))\n","model.add(Flatten())\n","model.add(Dense(2, activation='softmax'))\n","\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","# Train the model\n","model.fit(images, labels, validation_split=0.2, epochs=10)\n","\n","model.history\n","\n","\n","\n","# Set path for the test dataset\n","test_path = '/kaggle/input/494-fox-labeled-image-dataset/images.cv_8rk8h3aklzqjr2tcx76b7/data/test/animal fox'\n","\n","\n","# Create lists to store the test images and labels\n","test_images = []\n","test_labels = []\n","\n","\n","# Loop through the test directory and read in the images\n","for filename in os.listdir(test_path):\n","    if filename.endswith('.jpg'):\n","        img = Image.open(test_path + '/' + filename)\n","        test_images.append(np.array(img))\n","        test_labels.append(1) # Assume all images are of foxes\n","\n","\n","# Convert the test images and labels to numpy arrays\n","test_images = np.array(test_images)\n","test_labels = np.array(test_labels)\n","\n","\n","# Normalize the test images\n","test_images = test_images / 255.0\n","\n","\n","# One-hot encode the test labels\n","test_labels = to_categorical(test_labels)\n","\n","\n","# Evaluate the model on the test data\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(\"\")\n","print(\"Test loss:\", test_loss)\n","print(\"Test accuracy:\", test_acc)"]},{"cell_type":"markdown","id":"b476e87b","metadata":{"papermill":{"duration":0.008401,"end_time":"2023-02-12T23:37:33.46999","exception":false,"start_time":"2023-02-12T23:37:33.461589","status":"completed"},"tags":[]},"source":["This code is using the model.predict() function to generate predictions for the test images, which are images located in the specified test_path. The model.predict() function returns a probability for each class, in this case, fox or not fox. The predictions variable will contain an array of shape (n, 2) where n is the number of images in the test_path and 2 is the number of classes. Each row of the predictions array will contain the probability for each class. The output of the print function would be the softmax output of the model for each image of the test set."]},{"cell_type":"code","execution_count":2,"id":"4021f02b","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-12T23:37:33.489929Z","iopub.status.busy":"2023-02-12T23:37:33.488759Z","iopub.status.idle":"2023-02-12T23:37:33.636109Z","shell.execute_reply":"2023-02-12T23:37:33.634802Z"},"papermill":{"duration":0.160183,"end_time":"2023-02-12T23:37:33.638893","exception":false,"start_time":"2023-02-12T23:37:33.47871","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Generate a prediction\n","Prediction: [[0. 1.]]\n","Prediction shape: (1, 2)\n"]}],"source":["# Generate a prediction using model.predict() and calculate it's shape:\n","print(\"\")\n","print(\"Generate a prediction\")\n","prediction = model.predict(test_images[:1])\n","print(\"Prediction:\", prediction)\n","print(\"Prediction shape:\", prediction.shape)"]},{"cell_type":"markdown","id":"59c22fbd","metadata":{"papermill":{"duration":0.00863,"end_time":"2023-02-12T23:37:33.657001","exception":false,"start_time":"2023-02-12T23:37:33.648371","status":"completed"},"tags":[]},"source":["Note that this is a basic example, and you may need to adjust the code to suit your specific dataset and requirements. Also, the model architecture and parameters used here are simple and may not work well in practice."]},{"cell_type":"markdown","id":"5c87c477","metadata":{"papermill":{"duration":0.009275,"end_time":"2023-02-12T23:37:33.675268","exception":false,"start_time":"2023-02-12T23:37:33.665993","status":"completed"},"tags":[]},"source":["# Here is an improved version:"]},{"cell_type":"code","execution_count":3,"id":"3dc0f7ff","metadata":{"execution":{"iopub.execute_input":"2023-02-12T23:37:33.695389Z","iopub.status.busy":"2023-02-12T23:37:33.694635Z","iopub.status.idle":"2023-02-12T23:38:11.340222Z","shell.execute_reply":"2023-02-12T23:38:11.338272Z"},"papermill":{"duration":37.658623,"end_time":"2023-02-12T23:38:11.342649","exception":false,"start_time":"2023-02-12T23:37:33.684026","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","7/7 [==============================] - 5s 569ms/step - loss: 0.1202 - accuracy: 0.9072 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 2/10\n","7/7 [==============================] - 3s 457ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 3/10\n","7/7 [==============================] - 3s 459ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 4/10\n","7/7 [==============================] - 3s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 5/10\n","7/7 [==============================] - 3s 455ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 6/10\n","7/7 [==============================] - 3s 463ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 7/10\n","7/7 [==============================] - 3s 464ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 8/10\n","7/7 [==============================] - 3s 479ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 9/10\n","7/7 [==============================] - 4s 502ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 10/10\n","7/7 [==============================] - 4s 499ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","3/3 [==============================] - 0s 114ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n","\n","Test loss: 0.0\n","Test accuracy: 1.0\n"]}],"source":["# Import necessary libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","# Set path for the dataset\n","path = '/kaggle/input/494-fox-labeled-image-dataset/images.cv_8rk8h3aklzqjr2tcx76b7/data/train/animal fox'\n","\n","\n","# Create list to store the images and labels\n","images = []\n","labels = []\n","\n","\n","# Loop through the directory and read in the images\n","for filename in os.listdir(path):\n","    if filename.endswith('.jpg'):\n","        img = Image.open(path + '/' + filename)\n","        images.append(np.array(img))\n","        labels.append(1) # Assume all images are of foxes\n","\n","\n","# Convert the images and labels to numpy arrays\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","\n","# Normalize the images\n","images = images / 255.0\n","\n","\n","# One-hot encode the labels\n","labels = to_categorical(labels)\n","\n","\n","# Get the shape of the first image to use as input_shape for the first layer\n","img_shape = images[0].shape\n","\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","\n","# Create the model\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=img_shape))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(2, activation='softmax'))\n","\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","# Train the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n","\n","model.history\n","\n","\n","\n","# Set path for the test dataset\n","test_path = '/kaggle/input/494-fox-labeled-image-dataset/images.cv_8rk8h3aklzqjr2tcx76b7/data/test/animal fox'\n","\n","\n","# Create lists to store the test images and labels\n","test_images = []\n","test_labels = []\n","\n","\n","# Loop through the test directory and read in the images\n","for filename in os.listdir(test_path):\n","    if filename.endswith('.jpg'):\n","        img = Image.open(test_path + '/' + filename)\n","        test_images.append(np.array(img))\n","        test_labels.append(1) # Assume all images are of foxes\n","\n","\n","# Convert the test images and labels to numpy arrays\n","test_images = np.array(test_images)\n","test_labels = np.array(test_labels)\n","\n","\n","# Normalize the test images\n","test_images = test_images / 255.0\n","\n","\n","# One-hot encode the test labels\n","test_labels = to_categorical(test_labels)\n","\n","\n","# Evaluate the model on the test data\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(\"\")\n","print(\"Test loss:\", test_loss)\n","print(\"Test accuracy:\", test_acc)"]},{"cell_type":"code","execution_count":4,"id":"4af7bc4a","metadata":{"execution":{"iopub.execute_input":"2023-02-12T23:38:11.37662Z","iopub.status.busy":"2023-02-12T23:38:11.376051Z","iopub.status.idle":"2023-02-12T23:38:11.564633Z","shell.execute_reply":"2023-02-12T23:38:11.563007Z"},"papermill":{"duration":0.21083,"end_time":"2023-02-12T23:38:11.568631","exception":false,"start_time":"2023-02-12T23:38:11.357801","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Generate a prediction\n","Prediction: [[0. 1.]]\n","Prediction shape: (1, 2)\n"]}],"source":["# Generate a prediction using model.predict() and calculate it's shape:\n","print(\"\")\n","print(\"Generate a prediction\")\n","prediction = model.predict(test_images[:1])\n","print(\"Prediction:\", prediction)\n","print(\"Prediction shape:\", prediction.shape)"]},{"cell_type":"markdown","id":"1d688f04","metadata":{"execution":{"iopub.execute_input":"2023-01-22T12:49:21.460653Z","iopub.status.busy":"2023-01-22T12:49:21.460338Z"},"papermill":{"duration":0.014687,"end_time":"2023-02-12T23:38:11.599303","exception":false,"start_time":"2023-02-12T23:38:11.584616","status":"completed"},"tags":[]},"source":["This improved version of the code:\n","\n","- Use train_test_split to split the data into train and test sets. This is a good practice to avoid overfitting and generalize the model better.\n","- Add MaxPooling2D layer to reduce the spatial dimensions of the feature maps, reduce the number of parameters and computation.\n","- Add Dropout layers to prevent overfitting by randomly disabling some of the neurons in the model during training.\n","- Add a dense layer with 128 units and relu activation before the output layer\n","- Also, the input shape of the first layer is passed as parameter.\n","- This model architecture and parameters are still simple, but this is improved than the previous version and may work better in practice."]},{"cell_type":"markdown","id":"7478ea6f","metadata":{"papermill":{"duration":0.014511,"end_time":"2023-02-12T23:38:11.628807","exception":false,"start_time":"2023-02-12T23:38:11.614296","status":"completed"},"tags":[]},"source":["In the context of neural network training, an epoch is one full pass through the entire training dataset. During an epoch, the model's parameters are updated based on the error it made in predicting the output for the training examples. The number of epochs is a hyperparameter that determines the number of times the learning algorithm will work through the entire training dataset.\n","\n","When training a model, it's common to use a large number of epochs (e.g. 50, 100, or even more) to ensure that the model has seen the entire training dataset multiple times, and has had ample opportunity to learn the patterns in the data. However, as the model continues to train, it will eventually reach a point where additional epochs will not significantly improve the model's performance. This is known as overfitting, where the model becomes too specialized to the training data and perform badly on new unseen data.\n","\n","That's why it's important to monitor the performance of the model on a validation set during training, and stop training once the performance on the validation set stops improving or starts to degrade.\n","\n","In the example provided, 10 epochs are used. This is a relatively small number of epochs and the model may not have enough time to converge, it's a good practice to increase the number of epochs and check the performance of the model by monitoring the accuracy and loss during the training."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":77.888487,"end_time":"2023-02-12T23:38:14.991171","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-02-12T23:36:57.102684","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}